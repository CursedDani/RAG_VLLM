# ğŸ¤– Sistema RAG HÃ­brido con vLLM

Un sistema avanzado de Retrieval-Augmented Generation (RAG) que combina bÃºsqueda vectorial y textual para proporcionar respuestas precisas basadas en documentos. Especializado para consultas sobre polÃ­ticas de seguridad de la informaciÃ³n y protecciÃ³n de datos. puede ser usado para otros casos de uso entrenando un modelo y ingestando los documentos necesarios.

## ğŸš€ CaracterÃ­sticas Principales

### âœ¨ RAG HÃ­brido Avanzado
- **BÃºsqueda Vectorial**: Usando PostgreSQL con pgvector para similitud semÃ¡ntica
- **BÃºsqueda Textual**: Ãndice Lunr para coincidencias exactas de tÃ©rminos
- **FusiÃ³n RRF**: Reciprocal Rank Fusion para combinar resultados optimalmente
- **Re-ranking**: CrossEncoder para mejorar la relevancia final

### ğŸ”§ TecnologÃ­as Core
- **vLLM**: GeneraciÃ³n de texto y embeddings de alta performance
- **PostgreSQL + pgvector**: Base de datos vectorial escalable
- **Streamlit**: Interfaz web interactiva
- **Marker**: Procesamiento avanzado de documentos DOCX
- **Transformers**: Modelos de embedding y tokenizaciÃ³n

### ğŸ“„ Procesamiento de Documentos
- Soporte nativo para archivos DOCX
- ExtracciÃ³n inteligente de texto y tablas
- Chunking adaptativo con solapamiento
- PreservaciÃ³n de estructura de documentos

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Documentos    â”‚    â”‚   Procesamiento â”‚    â”‚   Almacenamientoâ”‚
â”‚     DOCX        â”‚â”€â”€â”€â–¶â”‚     Marker      â”‚â”€â”€â”€â–¶â”‚   PostgreSQL    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   + pgvector    â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   Interfaz      â”‚    â”‚   RAG HÃ­brido   â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚   Streamlit     â”‚â—€â”€â”€â”€â”‚   Orchestrator  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚      vLLM       â”‚
                       â”‚   Embeddings    â”‚
                       â”‚  + GeneraciÃ³n   â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de BÃºsqueda HÃ­brida

1. **Query del Usuario** â†’ Procesamiento en paralelo
2. **BÃºsqueda Vectorial** â†’ Embeddings + Similitud coseno
3. **BÃºsqueda Textual** â†’ Ãndice Lunr + TF-IDF
4. **FusiÃ³n RRF** â†’ Combina rankings con pesos optimizados
5. **Re-ranking** â†’ CrossEncoder para refinamiento final
6. **GeneraciÃ³n** â†’ vLLM produce respuesta contextualizada

## ğŸ“‹ Prerrequisitos

- **Python 3.8+**
- **PostgreSQL 12+** con extensiÃ³n pgvector
- **vLLM Server** configurado y ejecutÃ¡ndose
- **8GB+ RAM** recomendado para modelos de embedding

## ğŸ› ï¸ InstalaciÃ³n

### 1. Clonar el Repositorio
```bash
git clone <tu-repositorio>
cd rag_vllm
```

### 2. Crear Entorno Virtual
```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# Linux/Mac
source .venv/bin/activate
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar PostgreSQL con pgvector

```bash
#Windows
docker run -d   --name postgres   -e POSTGRES_USER=dani   -e POSTGRES_PASSWORD=dani   -e POSTGRES_DB=postgres   -p 5432:5432   ankane
/pgvector

docker exec -it postgres psql -U dani -d postgres

#Linux
sudo docker run -d   --name postgres   -e POSTGRES_USER=dani   -e POSTGRES_PASSWORD=dani   -e POSTGRES_DB=postgres   -p 5432:5432   ankane
/pgvector

sudo docker exec -it postgres psql -U dani -d postgres
```

```sql
-- Crear base de datos
CREATE DATABASE postgres;

-- Conectar a la base de datos
\c postgres;

-- Instalar extensiÃ³n pgvector
CREATE EXTENSION vector;

-- Verificar instalaciÃ³n
SELECT * FROM pg_extension WHERE extname = 'vector';
```

### 5. Configurar Variables de Entorno

Crear archivo `.env` en la raÃ­z del proyecto:

```env
# ConfiguraciÃ³n vLLM
VLLM_ENDPOINT=http://xxx.xxx.xxx.xxx:8002
#Asegurate que el puerto sea el 8002 pues se usarÃ¡ la estructura de OpenAI URL:PORT/v1/chat/completions
VLLM_EMBED=http://xxx.xxx.xxx.xxx:8003/embed
VLLM_MODEL_GENERATION=tu-modelo-generativo

# Base de datos
DB_CONNECTION_STRING="host=xxx.xxx.xxx.xxx dbname=postgres user=usuario_db password=contraseÃ±a_db"
```

### 6. Crear Estructura de Directorios
```bash
mkdir -p data data/docx data/docs data/qa_pairs
```

## ğŸ“š Uso

### 1. Preparar Documentos
Coloca tus archivos DOCX en la carpeta `data/docs/`, aÃ±ade el logo de tigo y el Ã­cono del bot:
```
data/
â”œâ”€â”€ Bot_icon.png
â”œâ”€â”€ Tigo_logo.png
â””â”€â”€ docs/
    â”œâ”€â”€ documento1.docx
    â”œâ”€â”€ documento2.docx
    â””â”€â”€ ...
```

### 2. Aplicar la limpieza antes de la ingesta

Luego de tener todos los documentos en la ruta necesaria se corre el script de limpieza.

```bash
python scripts/docx_cleanup.py
```
### 3. Procesar e Ingestar Documentos

Tras tener los documentos limpios y verificar que existan en la carpeta data/docx se aplica la ingesta.
```bash
python scripts/ingest.py
```

### 4. (opcional) Ingestar pares pregunta-respuesta
si se cuenta con pares de pregunta-respuesta se deben subir en un documento docx en la carpeta data/qa_pairs/ con el formato:

"Pregunta: Â¿DÃ³nde estÃ¡ la polÃ­tica de seguridad de la informaciÃ³n?
Respuesta: Puedes encontrar la polÃ­tica de seguridad de la informaciÃ³n en el siguiente vinculo: https://millicom.sharepoint.com/sites/ep-tigoco/Corporativo/Documents/Forms/AllItems.aspx?id=%2Fsites%2Fep%2Dtigoco%2FCorporativo%2FDocuments%2FPol%C3%ADticas%2FOperaciones%2FMIC%2DPOL%2DIS%2DInformation%20Security%20Policy%2DESP%2Epdf&parent=%2Fsites%2Fep%2Dtigoco%2FCorporativo%2FDocuments%2FPol%C3%ADticas%2FOperaciones 
-------
Pregunta: Â¿DÃ³nde estÃ¡ la polÃ­tica de seguridad?
Respuesta: Puedes encontrar la polÃ­tica de seguridad de la informaciÃ³n en el siguiente vinculo: https://millicom.sharepoint.com/sites/ep-tigoco/Corporativo/Documents/Forms/AllItems.aspx?id=%2Fsites%2Fep%2Dtigoco%2FCorporativo%2FDocuments%2FPol%C3%ADticas%2FOperaciones%2FMIC%2DPOL%2DIS%2DInformation%20Security%20Policy%2DESP%2Epdf&parent=%2Fsites%2Fep%2Dtigoco%2FCorporativo%2FDocuments%2FPol%C3%ADticas%2FOperaciones 
-------
"

Tras tener este documento con el formato de preguntas-respuestas se ejecuta

```bash
python scripts/ingest_QA.py
```

### 5. Ejecutar la AplicaciÃ³n
```bash
streamlit run app/ui_main.py
```

### 6. Interactuar con el Sistema
1. Abre tu navegador en `http://localhost:8501`
2. Escribe tu pregunta sobre el contenido de los documentos
3. El sistema realizarÃ¡ bÃºsqueda hÃ­brida y generarÃ¡ una respuesta contextualizada

## ğŸ“ Estructura del Proyecto

```
rag_vllm/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ ui_main.py              # Interfaz Streamlit principal
â”‚   â”œâ”€â”€ ui_main_copy.py         # Interfaz con integraciÃ³n de herramientas
â”‚   â”œâ”€â”€ rag_logic.py            # LÃ³gica RAG hÃ­brida
â”‚   â”œâ”€â”€ tools_interface.py      # Interface para herramientas de automatizaciÃ³n
â”‚   â”œâ”€â”€ chat_manager.py         # Gestor de conversaciones
â”‚   â””â”€â”€ prompts/
â”‚       â”œâ”€â”€ system_prompt.txt           # Prompt del sistema base
â”‚       â”œâ”€â”€ Security.txt                # Prompt para seguridad
â”‚       â”œâ”€â”€ Security_with_tools.txt     # Prompt con function calling
â”‚       â””â”€â”€ Security_with_json_tools.txt # Prompt con JSON tool calling
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ingest.py               # Ingesta con python-docx
â”‚   â”œâ”€â”€ ingest_QA.py            # Ingesta de pares de preguntas-Respuestas
â”‚   â””â”€â”€ docx_cleanup.py         # Limpieza de documentos para la ingesta
â”œâ”€â”€ automation/
â”‚   â”œâ”€â”€ acc_status.py           # ExtracciÃ³n de tickets de Acceso
â”‚   â”œâ”€â”€ pass_status.py          # ExtracciÃ³n de tickets de ContraseÃ±a
â”‚   â”œâ”€â”€ full_status.py          # ExtracciÃ³n completa multi-tipo
â”‚   â””â”€â”€ pptr/                   # AutomatizaciÃ³n con Puppeteer
â”‚       â”œâ”€â”€ final_automation.js     # ExtracciÃ³n de Change Orders
â”‚       â”œâ”€â”€ inc_extraction.js       # ExtracciÃ³n de Incidents
â”‚       â”œâ”€â”€ rq_extraction.js        # ExtracciÃ³n de Requests
â”‚       â”œâ”€â”€ package.json            # Dependencias Node.js
â”‚       â””â”€â”€ *_gui.html              # Interfaces grÃ¡ficas opcionales
â”œâ”€â”€ output/                     # Archivos JSON generados por automatizaciÃ³n
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ docx/                   # Documentos DOCX a insertar en la base de datos
â”‚   â”œâ”€â”€ docs/                   # Documentos originales, antes de aplicar la limpieza
â”‚   â”œâ”€â”€ qa_pairs/               # Documentos(s) con pares de pregunta-respuesta para ingestar
â”‚   â”œâ”€â”€ Tigo_logo.png
â”‚   â””â”€â”€ Bot_icon.png
â”œâ”€â”€ mcp-server/                 # Model Context Protocol server
â”‚   â””â”€â”€ server.py
â”œâ”€â”€ venv/                       # Entorno virtual
â”œâ”€â”€ requirements.txt            # Dependencias completas
â”œâ”€â”€ requirements-docker.txt     # Dependencias para Docker
â”œâ”€â”€ docker-compose.yml          # ConfiguraciÃ³n Docker con VPN
â”œâ”€â”€ Dockerfile                  # Imagen Docker
â”œâ”€â”€ api_server.py               # Servidor API REST
â”œâ”€â”€ api_client.py               # Cliente API
â”œâ”€â”€ .env                        # Variables de entorno
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```



## ğŸ” Troubleshooting

### Error de ConexiÃ³n vLLM
```
Error: No se pudieron cargar los recursos necesarios
```
**SoluciÃ³n**: Verificar que vLLM estÃ© ejecutÃ¡ndose:
```bash
curl http://xxx.xxx.xxx.xxx:8002/v1/models
```

### Error PostgreSQL
```
Error conectando a PostgreSQL
```
**SoluciÃ³n**: 
1. Verificar que PostgreSQL estÃ© corriendo
2. Instalar pgvector: `CREATE EXTENSION vector;`
3. Revisar string de conexiÃ³n en `.env`

### Problemas de InstalaciÃ³n

#### Dependencias PyTorch/CUDA
Si tienes problemas con PyTorch en GPU:
```bash
# CPU only (mÃ¡s ligero)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu

# CUDA 11.8 (si tienes GPU NVIDIA)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

#### PostgreSQL psycopg2 Issues
En algunos sistemas, `psycopg2-binary` puede fallar:
```bash
# Ubuntu/Debian
sudo apt-get install postgresql-dev python3-dev

# Windows (usar conda)
conda install psycopg2

# macOS
brew install postgresql
```


## ğŸ¤– Sistema de AutomatizaciÃ³n

El proyecto incluye dos sistemas de automatizaciÃ³n complementarios para extraer informaciÃ³n de CA Service Desk Manager:

### 1. AutomatizaciÃ³n Python (DirectAccess)

Scripts Python ubicados en `automation/` que utilizan la API interna de CA Service Desk:

#### Scripts Disponibles

- **`acc_status.py`**: Extrae estado de tickets de Acceso
- **`pass_status.py`**: Extrae estado de tickets de ContraseÃ±a  
- **`full_status.py`**: Extrae informaciÃ³n completa de mÃºltiples tipos de tickets

#### Uso Individual

```bash
# Ejecutar desde la raÃ­z del proyecto
python automation/acc_status.py <TICKET_NUMBER>
python automation/pass_status.py <TICKET_NUMBER>
python automation/full_status.py <TICKET_NUMBER>
```

#### CaracterÃ­sticas
- âœ… Acceso directo a la API interna de CA Service Desk
- âœ… ExtracciÃ³n rÃ¡pida y estructurada
- âœ… Salida en formato JSON
- âš ï¸ Requiere conectividad a la red interna (VPN)

### 2. AutomatizaciÃ³n Puppeteer (Web Scraping)

Scripts Node.js ubicados en `automation/pptr/` que automatizan la interfaz web:

#### Scripts Disponibles

- **`final_automation.js`**: Extrae Ã³rdenes de cambio (Change Orders)
- **`inc_extraction.js`**: Extrae incidentes
- **`rq_extraction.js`**: Extrae solicitudes (Requests)

#### InstalaciÃ³n de Dependencias

```bash
cd automation/pptr
npm install
```

#### Uso Individual

```bash
cd automation/pptr

# Extraer orden de cambio
node final_automation.js CHG0012345

# Extraer incidente
node inc_extraction.js INC0067890

# Extraer solicitud
node rq_extraction.js RQ0054321
```

#### CaracterÃ­sticas
- âœ… AutomatizaciÃ³n completa de la interfaz web
- âœ… ExtracciÃ³n de datos detallados incluyendo Workflow Tasks
- âœ… Salida en JSON (consola + archivo)
- âœ… Modo headless (sin interfaz grÃ¡fica)
- âœ… Capturas de pantalla en caso de error
- âš ï¸ Requiere conectividad a la red interna (VPN)

#### Salida de Datos

Cada script genera:
1. **Salida JSON en consola**: Una lÃ­nea JSON para consumo por API
2. **Archivo JSON en `output/`**: Archivo timestamped para respaldo
   - Formato: `{tipo}_{numero}_{timestamp}.json`
   - Ejemplo: `change_order_CHG0012345_2025-11-20T19-15-08-604Z.json`

#### Estructura de Datos ExtraÃ­dos

**Change Orders (`final_automation.js`):**
```json
{
  "changeOrderData": {
    "requester": "Usuario Solicitante",
    "affected_end_user": "Usuario Afectado",
    "category": "CategorÃ­a",
    "status": "Estado",
    "order_description": "DescripciÃ³n"
  },
  "workflowTasks": [
    {
      "sequence": "1",
      "task": "Nombre de Tarea",
      "description": "DescripciÃ³n",
      "assignee": "Asignado",
      "status": "Estado",
      "start_date": "Fecha Inicio",
      "completion_date": "Fecha Completado"
    }
  ]
}
```

**Incidents (`inc_extraction.js`):**
```json
{
  "incidentData": {
    "requester": "Solicitante",
    "affected_end_user": "Usuario Afectado",
    "category": "CategorÃ­a",
    "status": "Estado",
    "priority": "Prioridad",
    "severity": "Severidad",
    "summary": "Resumen",
    "incident_description": "DescripciÃ³n"
  }
}
```

**Requests (`rq_extraction.js`):**
```json
{
  "requestData": {
    "requester": "Solicitante",
    "affected_end_user": "Usuario Afectado",
    "category": "CategorÃ­a",
    "status": "Estado",
    "priority": "Prioridad",
    "summary": "Resumen",
    "request_description": "DescripciÃ³n"
  }
}
```

### ğŸ³ Uso con Docker + VPN

Para ejecutar las automatizaciones desde un contenedor Docker con acceso VPN:

#### 1. Configurar Docker Compose

El archivo `docker-compose.yml` ya estÃ¡ configurado para:
- Montar el directorio `automation/` como volumen
- Instalar Node.js y dependencias de Puppeteer
- Mantener conectividad VPN

#### 2. Ejecutar AutomatizaciÃ³n en el Contenedor

```bash
# Iniciar contenedor con VPN
docker-compose up -d

# Ejecutar script Python
docker exec rag-vllm-app python automation/acc_status.py <TICKET_NUMBER>

# Ejecutar script Puppeteer
docker exec rag-vllm-app node automation/pptr/final_automation.js CHG0012345

# Ver logs
docker-compose logs -f app
```

#### 3. Acceder a Archivos de Salida

Los archivos JSON generados estÃ¡n disponibles en:
```bash
# Desde el host
ls -l output/

# Desde el contenedor
docker exec rag-vllm-app ls -l /app/output/
```

### ğŸ”§ IntegraciÃ³n con el Chatbot

Las automatizaciones estÃ¡n integradas con el sistema RAG a travÃ©s de `app/tools_interface.py`:

#### Herramientas Disponibles

```python
# En el chatbot, el LLM puede invocar:
{
  "tool": "extract_change_order",
  "args": {"change_order_number": "CHG0012345"}
}

{
  "tool": "extract_incident", 
  "args": {"incident_number": "INC0067890"}
}

{
  "tool": "extract_request",
  "args": {"request_number": "RQ0054321"}
}
```

El chatbot automÃ¡ticamente:
1. Detecta cuÃ¡ndo se necesita informaciÃ³n de tickets
2. Ejecuta el script de automatizaciÃ³n correspondiente
3. Parsea el resultado JSON
4. Presenta la informaciÃ³n al usuario de forma estructurada

### ğŸ“ Notas Importantes

#### Requisitos de Red
- **Ambos sistemas** requieren acceso a la red interna de CA Service Desk
- Para uso fuera de la red corporativa, se necesita **conexiÃ³n VPN activa**
- El contenedor Docker debe tener acceso a la VPN del host

#### Credenciales
Las credenciales estÃ¡n hardcodeadas en los scripts de Puppeteer:
- Usuario: `rinforma`
- ContraseÃ±a: `ChatBot2025/*-+`

âš ï¸ **Seguridad**: En producciÃ³n, estas credenciales deberÃ­an estar en variables de entorno.

#### AutenticaciÃ³n Cross-Platform (Windows/Linux)

El servidor API (`api_server.py`) usa autenticaciÃ³n **hÃ­brida** con fallback automÃ¡tico:

##### MÃ©todo Principal: Kerberos (SASL)
- **Linux**: Usa `gssapi` con tickets Kerberos (`kinit`)
- **Windows**: Usa SSPI nativo de Windows
- **Ventaja**: No requiere credenciales en cÃ³digo (usa tickets del sistema)


##### ConfiguraciÃ³n Kerberos (Opcional)

**Linux**:
```bash
# Instalar dependencias del sistema
sudo dnf install krb5-workstation krb5-devel  # Fedora/RHEL
sudo apt-get install krb5-user libkrb5-dev    # Debian/Ubuntu

# Instalar paquete Python
pip install gssapi

# Obtener ticket Kerberos
kinit rinforma@EPMTELCO.COM.CO

# Verificar ticket
klist
```

**Windows**:
```powershell
# Kerberos SSPI estÃ¡ integrado en Windows
# No requiere instalaciÃ³n adicional

# El mÃ³dulo ldap3 usa automÃ¡ticamente SSPI
# Solo asegurar que el usuario tenga ticket Kerberos del dominio
```

##### ConfiguraciÃ³n Actual

El cÃ³digo detecta automÃ¡ticamente el sistema operativo:

```python
def create_ldap_connection():
    # Intenta Kerberos primero
    try:
        if platform.system() == 'Windows':
            # Windows SSPI Kerberos
            conn = Connection(server, authentication=SASL, 
                            sasl_mechanism=KERBEROS, auto_bind=True)
        else:
            # Linux gssapi Kerberos
            conn = Connection(server, user=AD_USER, 
                            authentication=SASL, sasl_mechanism=KERBEROS, 
                            auto_bind=True)
        return conn
    except Exception:
        # Fallback a NTLM si Kerberos falla
        conn = Connection(server, user='EPMTELCO\\rinforma', 
                         password=AD_PASSWORD, authentication=NTLM, 
                         auto_bind=True)
        return conn
```

##### Estado de ImplementaciÃ³n

- âœ… **CÃ³digo configurado** para Kerberos con fallback NTLM
- âœ… **DetecciÃ³n automÃ¡tica** de Windows/Linux
- âš ï¸ **Dependencia `gssapi`** no instalada en Linux (fallback activo)
- âœ… **NTLM funciona** como fallback en ambas plataformas

##### PrÃ³ximos Pasos (Opcional)

Para habilitar autenticaciÃ³n Kerberos pura:
1. Instalar dependencias del sistema (`krb5-devel`)
2. Instalar `gssapi` con `pip install gssapi`
3. Configurar `/etc/krb5.conf` con realm `EPMTELCO.COM.CO`
4. Obtener ticket con `kinit rinforma@EPMTELCO.COM.CO`
5. Remover variables `AD_PASSWORD` del cÃ³digo

#### Limpieza de Logs
Los scripts de Puppeteer han sido optimizados para:
- âŒ Sin logs de debug en consola
- âŒ Sin capturas de pantalla automÃ¡ticas
- âœ… Solo salida JSON estructurada
- âœ… Errores mÃ­nimos (solo crÃ­ticos)

Esto mejora la legibilidad cuando se integran con el chatbot.

### ğŸ› Troubleshooting de AutomatizaciÃ³n

#### Error: "ECONNREFUSED" (Puppeteer)
```
Error: connect ECONNREFUSED 10.100.85.31:80
```
**SoluciÃ³n**: Verificar conectividad VPN y acceso a CA Service Desk:
```bash
ping 10.100.85.31
curl http://10.100.85.31/CAisd/pdmweb1.exe
```

#### Error: "Ticket not found"
```
Error: No se encontrÃ³ informaciÃ³n del ticket
```
**SoluciÃ³n**: 
- Verificar que el nÃºmero de ticket sea correcto
- Verificar que el tipo de ticket coincida con el script usado
- Verificar permisos del usuario `rinforma`

#### Error: Chromium no encontrado (Puppeteer)
```
Error: Could not find Chromium
```
**SoluciÃ³n**:
```bash
cd automation/pptr
npm install puppeteer
# O reinstalar todo
rm -rf node_modules package-lock.json
npm install
```

#### Timeout en ExtracciÃ³n
Si los scripts toman demasiado tiempo o fallan por timeout:
- Verificar la velocidad de la conexiÃ³n VPN
- Aumentar timeouts en el cÃ³digo si es necesario
- Verificar que CA Service Desk estÃ© respondiendo

## ğŸ‘¥ Autores

- Juan Esteban Pineda - *Desarrollo inicial Bot Wifi* - [Esteban527](https://github.com/Esteban527)
- Daniel Felipe Arango GuarÃ­n - *Desarrollo inicial, AdaptaciÃ³n a seguridad* - [CursedDani](https://github.com/CursedDani)
